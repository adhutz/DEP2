---
title: "DEP2 Analyze workflow"
author: 
- name: Zhenhuan Feng
package: DEP2
output: 
  BiocStyle::html_document:
    toc_float: true
abstract: |
  This vigenette introduce proteiomics analysis workflow in DEP2 package. 
  This vigenette used the example dataset from a multiple omics study of silicosis mouse model.
vignette: |
  %\VignetteIndexEntry{DEP2: Proteomics Analyze}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = F,
  eval = T,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

```{r include=FALSE}
suppressPackageStartupMessages({
  # devtools::load_all()
  library("BiocStyle")
  library(tidyr)
  library(DEP2)
  library(SummarizedExperiment)
  library(tibble)
  library(tidyr)
  library(dplyr)
  library(ggplot2)
  library(missForest)
})
writeLines(capture.output(sessionInfo()), "sessionInfo.txt")
```

# Introduction
`DEP2` provides a differentially expressed/enriched analyze toolkits for mass spectrometry based quantitative proteomics data via `limma`, upgraded from a previous package `DEP`. This package provides an integrated workflow for proteomics analyze, including data processing, missing value imputation, hypothesis test, visualization and downstream function exploration. It accepts various of proteomics results generated by upstream search and quantitative software.

Now, `DEP2` provide three types of differentail proteomics analyze:

1. The pipeline for proteins-level expression/enrichment analysis, started from protein-level quantity.

    This pipeline is basically follows the methods in `DEP`, requires a protein-level quantity result (e.g. proteingroups.txt). 
    
2. The pipeline for proteins-level expression/enrichment analysis, started from peptide-level quantity.

    This pipeline clustered the peptide to protein summarization strategies in `QFeatures`, requires a protein-level quantity (e.g. proteingroups.txt). 
    
3. The pipeline for post-translation modification (PTM) specified proteomics, performed upon modified peptides quantity.

    This ppipline derived from the first one, and concludes the additional modification information in analysis.
    
# Input data
`DEP2` requires wide result table, and formats the identifiers (gene name and protein id in general) by `make_unique()` or `make_unique_ptm()`.

## Load protein-level data
Read in a proteingroup example (the quantitative result from MaxQuant), then format name and id of proteingroups.
```{r read-in,collapse=T}
## a proteinGroups data of a silicosis mouse model
data(Silicosis_pg) 
colnames(Silicosis_pg)

## Formatting name(gene symbol) and id(protein ID). 
## Generate a unique names for each protein. 
unique_pg <- make_unique(Silicosis_pg, names = "Gene.names", 
                         ids = "Protein.IDs", delim = ";") # names and ids are columns in table
## The duplicated names are uniqued by increasing decimal number.
unique_pg %>% filter(Gene.names!="") %>% group_by(Gene.names) %>% summarize(frequency = n(), names = paste0(name,collapse = ";")) %>% 
  arrange(desc(frequency)) %>% filter(frequency > 1) %>% head
```


Build a SummarizedExperiment object. DEP2 still use `r Biocpkg("SummarizedExperiment") ` objects as the analyze container to store expression assay,
features information (except expression value) and experiment design. Experiment design that label sample information is optional in workflow. DEP/DEP2
can except a table contains 'label', 'condition' and 'replicate' columns, or automatically assign it by column names parsing. 

```{r SE,collapse=T}
## Take expression columns(LFQ intensity in this cases).
ecols <- grep("LFQ.intensity.", colnames(unique_pg))

## Construct SE
### 1. import a experiment design table.
expdesign <- read.delim("../inst/example/Silicosis_expdesign.txt")
head(expdesign,6) # the example experiment design
se_pg <- DEP2::make_se(unique_pg, columns = ecols, expdesign = expdesign, 
                       log2transform = T)
class(se_pg)
head(assay(se_pg), 5) ## log2-transformed expression assay 

### 2. Generate a experiment design by parsing expression column names.
se_pg2 <- DEP2::make_se_parse(unique_pg, columns = ecols, mode = "delim", 
                              sep = "_", remove_prefix = T, log2transform = T)
```

## Load peptide quantification result for protein aggregation

The second pipeline is to calculate protein-level abundance by peptide summation. It can bypass the summation method in the upstream software.
DEP2 draw the protein aggregation though the `r Biocpkg("QFeatures") `, and use the `QFeatures` container to process peptide-level data. 
This pipeline requires a peptide result table contains both abundance assay and relative protein information (gene names or protein ID) for protein aggregation.

```{r}
## a peptides table from a silicosis mouse model.
data(Silicosis_peptide) 

(ecols <- grep("Intensity.", colnames(Silicosis_peptide), value = T)) 
pe_peptides <- make_pe_parse(Silicosis_peptide, columns = ecols,   # columns is the abundance columns
                             mode = "delim", sep = "_",
                             remove_prefix = T, log2transform = T) # log2transform 
pe_peptides # a QFeatures object, with a peptideRaw assay
colData(pe_peptides)
```

## Load the modified-site quantification result to perform differetial PTM analysis.

For, PTM-specific proteomics study, DEP2 design a new workflow similar from global proteomics analyze. 
In this pipeline, post-translation modification information is necessary to distinguish modified sites.
This pipeline required the unique identifier for distinguish different modified sites, 
modification information such as position, modified residue(amino acid), 
gene name or protein ID that modification is associated with.

```{r}
## phosphorylated peptides table of the silicosis mouse model.
data(Silicosis_phos) 

## Format the modification information and generated modified-peptides identifier.
## aa and pos is the modified amino acids and modified site in protein.
unique_pho <- make_unique_ptm(Silicosis_phos, gene_name = "Gene.names", 
                              protein_ID = "Protein", aa = "Amino.acid",
                              pos = "Position") 
```

`make_unique_ptm` creates(or overwrites) the PTM information columns, including 
*name*,*ID*,*gene_name*,*protein_ID*,*modified_aa*,*modified_pos*. The *name*,*ID* columns follow such naming ruleï¼š
'(gene name/protein ID)_(modified amino acid)(position of modification)' (e.g. "TBCA_K51" and "O75347_K51").

```{r}
## The formatted name and ID for PTM
unique_pho %>% select("name","ID","gene_name","protein_ID","modified_aa","modified_pos") %>% head(7)

## Take expression columns.
ecols <- grep("Intensity.", colnames(unique_pho))

## Construct a SE object mentioned before.
se_ptm <- DEP2::make_se_parse(unique_pho, columns = ecols, mode = "delim", sep = "_", remove_prefix = T, log2transform = T)
```


# Differentially expression analysis
DEP2 provide an entire workflow for each pipeline. Such

## Analysis for proteomics data

**Filter**

Undesired features, like reverse sequence or contaminant protein hits, may contain in the result table.
Besides, missing values (MVs) is inevasible label-free MS-based proteomics especially for DDA data.
Filter out reverse, contaminant, and low quality features with many missing are needless
 for following statistical test.
`filter_se` can filter features based on missing threshold or criterion on giving information.

```{r}
filter_pg <- filter_se(se_pg,
                       thr = 1,  ## the threshold of missing number in at least one condition
                       fraction = 0.3, ## the threshold of missing occupancy in each protein
                       filter_formula = ~ Reverse != '+' & Potential.contaminant !="+" ## filter upon Reverse and contaminant
                      )
## Further filter can perform though filter_formula.
## For example, keep proteingroups with at least one unique peptide in further analysis.
filter_pg <- filter_se(filter_pg,
                       filter_formula = ~ Unique.peptides > 0)

get_df_wide(se_pg)$Reverse %>% table
get_df_wide(filter_pg)$Reverse %>% table

(plot_coverage(se_pg) + ggtitle("Before filter")) + 
  (plot_coverage(filter_pg) + ggtitle("After filter"))

(plot_frequency(se_pg) + ggtitle("Identification overlap before filter")) / 
  (plot_frequency(filter_pg) + ggtitle("Identification overlap after before filter"))
```

**Normalization**

Assay should be log2-transformed during SE construction. 
In the DEP workflow, assay is further normalized by variance stabilizing transformation(vsn).
```{r message=FALSE}
norm_pg <- normalize_vsn(filter_pg)
plot_normalization(filter_pg, norm_pg)
```

**imputation**

A considerable proportion of remaining MVs still remain in the assay after filtering. 
```{r missing heatmap, message=FALSE}
plot_missval(filter_pg)
```

MVs can be divided into missing at random (MAR), missing at random (MAR) and missing not at random (MNAR), based on NA frequency intensity signal. Function `impute` draws kinds of imputation on SE object. Be same as DEP, `impute` cluster the imputation functions from `r Biocpkg("MSnbase")` and `r Biocpkg("MsCoreUtils")`, including following methods.

-- Left-censored imputation methods, replace:  *"MinDet", "MinProb", "min"(LOD), "QRILC", "zero", "man"(impute by a left-shifted distribution)*

-- local similarity methods: *"knn", "nbavg"*

-- Global-structure methods: *"MLE", "BPCA"*

Further detials can view the vignettes in `r Biocpkg("DEP")` and `r Biocpkg("MSnbase")`. In additional, DEP2 clusters two machine learning based imputation in `impute`: *"RF"* and *"GSimp"*. "RF" call the `missForest::missForest`, which train a random forest based on observed parts of dataset. And "GSimp" is a Gibbs sampler based left-censored imputation method proposed by [Runmin Wei, Jingye Wang, etc](https://doi.org/10.1371/journal.
pcbi.1005973). These two methods take a long time on iteration but are reported that could draw a better estimation on missing. 

```{r impute}
set.seed(35)
sample_rows <- sample(1:nrow(norm_pg), 300)
norm_pg_sample = norm_pg[sample_rows,] # random sample 150 features to reduce runing time
plot_detect(norm_pg_sample)

## Impute missing data using random draws from a Gaussian distribution centered around a minimal value (for MNAR)
imp_pg_MinProb <- impute(norm_pg_sample, fun = "MinProb", q = 0.01)

## Impute missing data using k-nearest neighbour approach
imp_pg_knn <- impute(norm_pg_sample, fun = "knn")

## Impute missing data using missForest
imp_pg_RF <- impute(norm_pg_sample, fun = "RF", ntree = 50, mtry = 5) 

## Impute missing data using Gibbs
imp_pg_GSimp <- impute(norm_pg_sample, fun = "GSimp", hi_q = 0.1,
                       iters_each=40, iters_all=8) 
```
The difference among imputation methods.
```{r message=FALSE}
plot_detect(norm_pg_sample)

NAs <- is.na(assay(norm_pg_sample)) 
## the imputed values by different methods.
imps <- list("GSimp" = imp_pg_GSimp, "MinProb" = imp_pg_MinProb, "RF" = imp_pg_RF, "knn" = imp_pg_knn) %>% 
  lapply(function(se){
    x = assay(se) %>% data.frame %>% gather("label", "value") %>% 
      left_join(colData(se)[c("label","condition")],copy = T) %>%
      magrittr::extract(as.vector(NAs),)
  }) %>% data.table::rbindlist(idcol = "method")

## the original normalized values without imputation
nonimps <- assay(norm_pg_sample) %>% data.frame %>% gather("label", "value") %>%
  left_join(colData(norm_pg_sample)[c("label","condition")],copy = T) %>% 
  magrittr::extract(!as.vector(NAs),) %>% mutate(method = "non_impute") %>%
  select(method,everything())

library(ggridges)
ggplot(rbind(imps, nonimps),aes(x = value,y = factor(method,level = unique(method)))) + 
  geom_density_ridges(fill = "#027ad450", scale = 1.2,
                      jittered_points = TRUE,position = position_points_jitter(height = 0),
                      point_shape = '|', point_size = 2, point_alpha = 1, alpha = 0.7) +
  ylab("Impute method")+ ylab("Log2 value") + xlim(c(9,39))+
  theme_DEP1()
```
Left-censored approaches, like MinProb and GSimp replace MVs, by conservatively low values; local similarity method "knn" and global data learning "RF" impute markedly larger values. .These two method cater to MNAR and MAR respectively. In these


```{r rmtemp}
rm(list = c("norm_pg_sample", "imp_pg_knn","imp_pg_MinProb","imp_pg_RF","imp_pg_GSimp"))
## Impute missing data using q-th quantile for following analyze
imp_pg <- impute(norm_pg, fun = "MinDet" ,q = 0.01)
```


**Hypothesis test**

Function `test_diff` perform a moderated t-test from limma. In DEP, p values is corrected by the `fdrtool` to classify significantly regulated/enriched candidates and stable proteins. DEP2 additionally provides two alternative frequently-used FDR control method, *"Benjamini-Hochberg fdr"* and *"Storey's qvalue"*. 

```{r testdiff}
## Test every sample versus PBS control
diff_pg <- test_diff(imp_pg, type = "control", control = "PBS")
## Test on manul contrasts
diff_pg <- test_diff(imp_pg, type = "manual", test  = c("W4_vs_PBS", "W6_vs_PBS"), fdr.type = "Storey's qvalue")
## Use fdrtool to correct adjusted p
diff_pg <- test_diff(imp_pg, type = "control", control = "PBS", fdr.type = "BH")
```

Function `add_rejections` can classify significant hits according L2FC (*lfc*) and adjusted p value (*alpha*) threshold.
```{r rejections1}
## Add significant rejection for features, based on 
dep_pg <- add_rejections(diff_pg, alpha = 0.01, lfc = 2)
## get significant subset
dep_pg_sig <- get_signicant(dep_pg)
nrow(dep_pg_sig)
```
`plot_volcano` to have a quick look on result.
```{r rejections plot 1}
### volcano plot on contrast "W4_vs_PBS"
plot_volcano(dep_pg, contrast = "W4_vs_PBS", adjusted = F)
## plot the cutoff line
plot_volcano(dep_pg, contrast = "W4_vs_PBS", adjusted = F,
             add_threshold_line = "intersect", pCutoff  = 0.05, fcCutoff = 1)
```

Besides the intersect method, add_rejections can draw a curve cutoff approach described by [Eva C.Keilhauer](https://www.sciencedirect.com/science/article/pii/S1535947620316674). Instead of intersect straight lines, the approach used 
curve lines with $y > c/(x - x_0)$, where $x$ is the log2 FC, $y$ is adjusted P value of features (*c* = curvature, *x[0]* = minimum L2FC). 
We use the standard deviation $\sigma$ determine x0 by $x_0 = x_0.fold*\sigma$. $\sigma$ is the standard deviation of the Gaussian curve distribution of log2 FC in each contrast.

```{r rejections2}
## thresholdmethod = "curve"
dep_pg_curve <- add_rejections(diff_pg, thresholdmethod = "curve", curvature  = 2, x0_fold = 2)
## the cutoff line on volcano
plot_volcano(dep_pg_curve, contrast = "W4_vs_PBS", add_threshold_line = "curve", curvature = 2, x0_fold = 2) /
  plot_volcano(dep_pg_curve, contrast = "W6_vs_PBS", add_threshold_line = "curve", curvature = 2, x0_fold = 2)
## Check the fitted gaussian curve
plot_diff_hist(dep_pg_curve, contrasts = c("W4_vs_PBS", "W6_vs_PBS"))
## get the fit result 
plot_diff_hist(dep_pg_curve, plot = F) ## a table of gaussian args \sigma and \mu
```

`plot_heatmap` can plot a heatmap for significant candidates.
```{r}
plot_heatmap(dep_pg)
## reorder columns by condition
dep_pg = DEP2::Order_cols(dep_pg,order = c("PBS","W2","W4","W6","W9","W10"))
plot_heatmap(dep_pg, cluster_columns = F, kmeans = T, k = 5, seed = 1) # cluster features
## only plot the clusters that are up-regulated in treatment groups.
plot_heatmap(dep_pg, cluster_columns = F, kmeans = T, k = 5, seed = 1, col_limit = 4,
             split_order = c(1,2,5)
             )
## plot on select contrast
plot_heatmap(dep_pg, manual_contrast = "W4_vs_PBS")
```

## Export table
```{r}
## get result table
DT::datatable(head(get_results(dep_pg)), options = list(scrollX = T))
## get full data set with row annotation.
DT::datatable(head(get_df_wide(dep_pg),3), options = list(scrollX = T))
## get significant table
DT::datatable(head(get_df_wide(dep_pg),3), options = list(scrollX = T))
```

## Analysis based on protein re-aggregation
The second pipeline is aggregation protein abundance from peptide quantity data.
The analyze workflow is different to last one in data processing steps.

```{r pe2}
pe_peptides # a QFeatures object imported above
```

**Filter**

QFeatures object can be filtered though by `filter_pe` which is similar to function `filter_se`
```{r filter pe}
## Sample 800 protein ID as example, to reduce computational cost in these vignette
set.seed(50)
sample_protein = sample(unique(Silicosis_peptide$Proteins),1000)
Silicosis_peptide2 <- dplyr::filter(Silicosis_peptide, Proteins %in% sample_protein)
pe_peptides2 <- filter_pe(pe_peptides, filter_formula = ~ Proteins %in% sample_protein)
pe_peptides2
## fitlt out low quality peptides
filt_pe <- filter_pe(pe_peptides2, thr = 1,fraction = 0.4, filter_formula = ~ Reverse != '+' & Potential.contaminant !="+" )
```

**imputation**

Imputation could perform before normalization, to reduce the potential effect of MVs to normalization. 
```{r imp pe, message=FALSE}
## Use QFeatures::addAssay() and DEP2::impute
imp_pe <- QFeatures::addAssay(filt_pe,
                              DEP2::impute(filt_pe[["peptideRaw"]], fun = "MinDet"), # use
                              name = "peptideImp")

plot_imputation(imp_pe[["peptideRaw"]], imp_pe[["peptideImp"]])
imp_pe # The complete assay is stored in peptideImp
```

**Normalization**

Function `normalize_pe` perform normalize and call `QFeatures:normalize`. 
Four normalization methods are selectable., including 
*"diff.median", "quantiles", "quantiles.robust" ,"vsn"*. 
Notice that *quantiles.robust* can't handle data table with missing (ie NA).
Therefore It is necessary to Imputate in advance .

```{r}
norm_pe <- DEP2:::normalize_pe(imp_pe,method = "quantiles",
                               i = "peptideImp", ## nomalize on which assay
                               name = "peptideNorm" ## output assay name
                               )
```

**Aggregation**
DEP2 packaged function `aggregate_pe` based on `QFeatures::aggregateFeatures`.
The summarisation approach *aggrefun* can be "RobustSummary", "medianPolish", "totalMean".
Details can see `?aggregateFeatures`.
And proteingroups can be summed by "Unique + Razor" or "Unique".

```{r aggrega}
## Unique peptides
# protein_pe_U <- DEP2::aggregate_pe(norm_pe,
#                            aggrefun = "RobustSummary",
#                            aggregate_Peptide_Type = "Unique",
#                            fcol = "Proteins",                  # the protein ID column in input table
#                            peptide_assay_name = "peptideNorm", # the assay to aggregate
#                            reserve = "Gene.names"              # reserve the Gene.names in row data.
#                            )

## Unique + Razor peptides
protein_pe <- DEP2::aggregate_pe(norm_pe,
                           aggrefun = "RobustSummary",
                           aggregate_Peptide_Type = "Unique + Razor",
                           fcol = "Proteins",                  # the protein ID column in input table
                           peptide_assay_name = "peptideNorm", # the assay to aggregate
                           reserve = "Gene.names"              # reserve the Gene.names in row data.
                           )
protein_pe ## protein result is in the protein assay
# SE_pep <- protein_pe[["protein"]]
# colnames(rowData(SE_pep))
# 
# ## make names for features
# rd <- DEP2::make_unique(rowData(SE_pep) %>% as.data.frame(),
#                                      names = "Gene.names",           # The gene names
#                                      ids = "smallestProteingroups",  # The protien ID translated to Proteingroups.
#                                      delim = ";")
# rownames(rd) <- rd$name
# rowData(SE_pep) <- rd
# rownames(SE_pep) <- rd$name

SE_pep <- pe2se(SE_pep)
rm(list = c("filt_pe", "imp_pe","norm_pe")) # rm intermediate variables
```

**Differential test**
Following differential test is same to the proteingroups pipeline. Use `test_diff` and `add_rejections` to classify significant protein.
```{r}
## check the sample data 
plot_normalization(SE_pep) 
plot_imputation(SE_pep)

## Differential test
diff_pep <- DEP2::test_diff(SE_pep,type = "control", control = "PBS", fdr.type = "Strimmer's qvalue(t)")
## Add rejections
dep_pep <- add_rejections(diff_pep)
get_signicant(dep_pep) %>% nrow
```

Data visualization functions is also worked for aggregation result
```{r DEP visualization}
## Volcano
plot_volcano(dep_pep, contrast = "W6_vs_PBS", add_threshold_line = "intersect") 
## Heatmap
plot_heatmap(dep_pep, kmeans = T,k = 5,col_limit = 6) 
```

## Analysis for PTM-specific proteomics

The third pipeline is analyze PTM-specific proteomics. It accept the quantification result table of modified sites. 
Data processing workflow is basicly similar to the PG analyze workflow.

**Filter** 
`filter_se` are universal function for SE object.
```{r}
## Filter base on both missing occupancy and the localization probability for this site.
filt_ptm <- filter_se(se_ptm, 
                     thr = 1, fraction = 0.3, 
                     filter_formula = ~ Reverse!="+" & Potential.contaminant!="+"&Localization.prob>0.7)

norm_ptm <- normalize_vsn(filt_ptm)

imp_ptm <- impute(filt_ptm, fun= "knn")

diff_ptm <- test_diff(imp_ptm, type = "manual", test = "PBS_vs_W6" , fdr.type = "BH")

dep_ptm <- DEP2::add_rejections(diff_ptm, alpha = 0.05, lfc = 1)
plot_volcano(dep_ptm,adjusted = T, add_threshold_line = "intersect")
class(dep_ptm)
```

























